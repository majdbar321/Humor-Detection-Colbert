{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3396416,"sourceType":"datasetVersion","datasetId":2047508},{"sourceId":5488242,"sourceType":"datasetVersion","datasetId":3167824},{"sourceId":5497643,"sourceType":"datasetVersion","datasetId":3172244}],"dockerImageVersionId":30461,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\njokes_df = pd.read_csv('/kaggle/input/200k-short-texts-for-humor-detection/dataset.csv')\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T14:32:48.356548Z","iopub.execute_input":"2023-04-23T14:32:48.357160Z","iopub.status.idle":"2023-04-23T14:32:48.904185Z","shell.execute_reply.started":"2023-04-23T14:32:48.357120Z","shell.execute_reply":"2023-04-23T14:32:48.902849Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Drop duplicate rows\njokes_df.drop_duplicates(subset=['text'], inplace=True)\n\n# Define a function to count words in a text\ndef word_count(text):\n    return len(text.split())\n\n# Filter rows based on character length and word length\njokes_df = jokes_df[(jokes_df['text'].str.len() >= 30) & (jokes_df['text'].str.len() <= 100) &\n                    (jokes_df['text'].apply(word_count) >= 5) & (jokes_df['text'].apply(word_count) <= 25)]\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T14:32:48.905587Z","iopub.execute_input":"2023-04-23T14:32:48.906083Z","iopub.status.idle":"2023-04-23T14:32:49.653289Z","shell.execute_reply.started":"2023-04-23T14:32:48.906009Z","shell.execute_reply":"2023-04-23T14:32:49.651945Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(jokes_df['text'], jokes_df['humor'], test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T14:32:49.656019Z","iopub.execute_input":"2023-04-23T14:32:49.656741Z","iopub.status.idle":"2023-04-23T14:32:49.694893Z","shell.execute_reply.started":"2023-04-23T14:32:49.656694Z","shell.execute_reply":"2023-04-23T14:32:49.693664Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Define a function to split text into sentences\nfrom textblob import TextBlob\n\ndef split_sentences(text):\n    return [str(sentence) for sentence in TextBlob(text).sentences]\n\n# Get sentence-wise embeddings for training and validation sets\nX_train_sentences = X_train.apply(split_sentences)\nX_val_sentences = X_val.apply(split_sentences)\n\n# Pad or truncate the sentences to have exactly 3 sentences per text\ndef pad_or_truncate_sentences(sentences_list, num_sentences=3):\n    if len(sentences_list) > num_sentences:\n        return sentences_list[:num_sentences]\n    else:\n        return sentences_list + [''] * (num_sentences - len(sentences_list))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T14:32:49.696435Z","iopub.execute_input":"2023-04-23T14:32:49.696820Z","iopub.status.idle":"2023-04-23T14:33:06.305580Z","shell.execute_reply.started":"2023-04-23T14:32:49.696785Z","shell.execute_reply":"2023-04-23T14:33:06.304224Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X_train_sentences = X_train_sentences.apply(pad_or_truncate_sentences)\nX_val_sentences = X_val_sentences.apply(pad_or_truncate_sentences)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T14:33:06.307126Z","iopub.execute_input":"2023-04-23T14:33:06.307490Z","iopub.status.idle":"2023-04-23T14:33:06.779922Z","shell.execute_reply.started":"2023-04-23T14:33:06.307455Z","shell.execute_reply":"2023-04-23T14:33:06.778760Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Load the embeddings from disk (later when you need them)\nimport numpy as np\n\nX_train_embeddings = np.load('/kaggle/input/embeddings-data/X_train_embeddings.npy')\nX_val_embeddings = np.load('/kaggle/input/embeddings-data/X_val_embeddings.npy')","metadata":{"execution":{"iopub.status.busy":"2023-04-23T14:33:06.781607Z","iopub.execute_input":"2023-04-23T14:33:06.781944Z","iopub.status.idle":"2023-04-23T14:33:25.607318Z","shell.execute_reply.started":"2023-04-23T14:33:06.781910Z","shell.execute_reply":"2023-04-23T14:33:25.605933Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import os\n\n# Load the embeddings from disk\ndef load_embeddings(prefix):\n    embeddings = []\n    i = 0\n    while True:\n        file_path = f'/kaggle/input/embeddings-data/{prefix}_embedding_{i}.npy'\n        if os.path.exists(file_path):\n            emb = np.load(file_path,allow_pickle=True)\n            embeddings.append(emb)\n            i += 1\n        else:\n            break\n    return embeddings\n\nX_train_sentence_embeddings = load_embeddings('X_train_sentence')\nX_val_sentence_embeddings = load_embeddings('X_val_sentence')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-23T14:33:25.609178Z","iopub.execute_input":"2023-04-23T14:33:25.609962Z","iopub.status.idle":"2023-04-23T14:34:18.334800Z","shell.execute_reply.started":"2023-04-23T14:33:25.609906Z","shell.execute_reply":"2023-04-23T14:34:18.333591Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Remove the extra element if present\nif X_train_sentence_embeddings[-1].shape != (len(X_train), 5, 512):\n    X_train_sentence_embeddings.pop()\n\nif X_val_sentence_embeddings[-1].shape != (len(X_val), 5, 512):\n    X_val_sentence_embeddings.pop()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T14:34:18.336142Z","iopub.execute_input":"2023-04-23T14:34:18.336448Z","iopub.status.idle":"2023-04-23T14:34:18.417454Z","shell.execute_reply.started":"2023-04-23T14:34:18.336416Z","shell.execute_reply":"2023-04-23T14:34:18.415984Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom textblob import TextBlob\nfrom transformers import BertTokenizer, TFBertModel\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Dense, Concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T14:34:18.422641Z","iopub.execute_input":"2023-04-23T14:34:18.423637Z","iopub.status.idle":"2023-04-23T14:34:18.430467Z","shell.execute_reply.started":"2023-04-23T14:34:18.423581Z","shell.execute_reply":"2023-04-23T14:34:18.429287Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\nmodel = load_model('/kaggle/input/model-beta/model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T14:34:18.431769Z","iopub.execute_input":"2023-04-23T14:34:18.432092Z","iopub.status.idle":"2023-04-23T14:34:19.202425Z","shell.execute_reply.started":"2023-04-23T14:34:18.432045Z","shell.execute_reply":"2023-04-23T14:34:19.201120Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the validation set\nscores = model.evaluate([X_val_embeddings] + X_val_sentence_embeddings, y_val, verbose=1)\nprint(\"Validation Accuracy: %.2f%%\" % (scores[1] * 100))","metadata":{"execution":{"iopub.status.busy":"2023-04-23T14:34:19.204082Z","iopub.execute_input":"2023-04-23T14:34:19.204513Z","iopub.status.idle":"2023-04-23T14:34:25.770807Z","shell.execute_reply.started":"2023-04-23T14:34:19.204464Z","shell.execute_reply":"2023-04-23T14:34:25.769521Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"1250/1250 [==============================] - 6s 4ms/step - loss: 0.2946 - accuracy: 0.9142\nValidation Accuracy: 91.42%\n","output_type":"stream"}]},{"cell_type":"code","source":"#y_pred = [inner_list[0] for inner_list in y_pred]\n#len(y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-04-23T02:58:09.554987Z","iopub.execute_input":"2023-04-23T02:58:09.555444Z","iopub.status.idle":"2023-04-23T02:58:09.564176Z","shell.execute_reply.started":"2023-04-23T02:58:09.555408Z","shell.execute_reply":"2023-04-23T02:58:09.562872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor i in range(5):\n    # Make predictions on the validation set\n    y_pred = model.predict([X_val_embeddings] + X_val_sentence_embeddings)\n\n    # Convert predicted probabilities to binary predictions\n    y_pred = np.where(y_pred > 0.5, 1, 0)\n    y_pred = [inner_list[i] for inner_list in y_pred]\n    # Calculate precision, recall, and F1-score\n    from sklearn.metrics import precision_recall_fscore_support\n    from sklearn.metrics import accuracy_score\n\n    precision, recall, f1, _ = precision_recall_fscore_support(y_val, y_pred, labels=[0, 1], average='binary')\n\n    # Calculate accuracy\n    accuracy = accuracy_score(y_val, y_pred)\n\n    print(\"Validation Accuracy: %.2f%%\" % (accuracy * 100))\n    print(\"Validation Precision: %.2f%%\" % (precision * 100))\n    print(\"Validation Recall: %.2f%%\" % (recall * 100))\n    print(\"Validation F1-score: %.2f%%\" % (f1 * 100))\n    print(\"-----------------\")\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T14:34:25.772237Z","iopub.execute_input":"2023-04-23T14:34:25.775420Z","iopub.status.idle":"2023-04-23T14:35:07.890377Z","shell.execute_reply.started":"2023-04-23T14:34:25.775363Z","shell.execute_reply":"2023-04-23T14:35:07.889095Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"1250/1250 [==============================] - 5s 4ms/step\nValidation Accuracy: 91.44%\nValidation Precision: 92.89%\nValidation Recall: 89.75%\nValidation F1-score: 91.29%\n-----------------\n1250/1250 [==============================] - 5s 4ms/step\nValidation Accuracy: 91.65%\nValidation Precision: 93.01%\nValidation Recall: 90.06%\nValidation F1-score: 91.52%\n-----------------\n1250/1250 [==============================] - 5s 4ms/step\nValidation Accuracy: 91.54%\nValidation Precision: 92.60%\nValidation Recall: 90.29%\nValidation F1-score: 91.43%\n-----------------\n1250/1250 [==============================] - 5s 4ms/step\nValidation Accuracy: 91.13%\nValidation Precision: 92.64%\nValidation Recall: 89.35%\nValidation F1-score: 90.97%\n-----------------\n1250/1250 [==============================] - 5s 4ms/step\nValidation Accuracy: 91.31%\nValidation Precision: 92.83%\nValidation Recall: 89.54%\nValidation F1-score: 91.16%\n-----------------\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras import metrics\n\nprecision = metrics.Precision(name='precision')\nrecall = metrics.Recall(name='recall')\n\n#adam 16 & leaky and more layers","metadata":{"execution":{"iopub.status.busy":"2023-04-22T17:01:49.719526Z","iopub.execute_input":"2023-04-22T17:01:49.721016Z","iopub.status.idle":"2023-04-22T17:01:49.871362Z","shell.execute_reply.started":"2023-04-22T17:01:49.720959Z","shell.execute_reply":"2023-04-22T17:01:49.869905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    # Define input layers\n    whole_text_input = Input(shape=(5, 512), dtype='float32', name='whole_text_input')\n    sentence_inputs = [Input(shape=(5, 512), dtype='float32', name=f'sentence_input_{i}') for i in range(2)]  # Change to 2 inputs\n\n    # Sentence-specific hidden layers\n    sentence_hidden_layers = []\n    for sentence_input in sentence_inputs:\n        hidden = Dense(20, activation='relu')(sentence_input)\n        hidden = Dense(40, activation='LeakyReLU')(sentence_input)\n\n        sentence_hidden_layers.append(hidden)\n\n    # Concatenate sentence-specific hidden layers\n    concatenated_sentences = Concatenate()(sentence_hidden_layers)\n\n    # Whole text hidden layers\n    whole_text_hidden = Dense(60, activation='relu')(whole_text_input)\n\n    # Combine sentence-specific and whole text hidden layers\n    combined = Concatenate()([concatenated_sentences, whole_text_hidden])\n\n    # Final hidden layers and output layer\n    hidden_1 = Dense(200, activation='LeakyReLU')(combined)\n    hidden_2 = Dense(180, activation='relu')(hidden_1)\n    hidden_3 = Dense(160, activation='LeakyReLU')(hidden_2)\n\n    hidden_4 = Dense(140, activation='relu')(hidden_3)\n\n    hidden_5 = Dense(120, activation='LeakyReLU')(hidden_4)\n    hidden_6 = Dense(100, activation='relu')(hidden_5)\n    hidden_7 = Dense(80, activation='LeakyReLU')(hidden_6)\n    hidden_8 = Dense(60, activation='relu')(hidden_7)\n    hidden_9 = Dense(40, activation='LeakyReLU')(hidden_8)\n    hidden_10 = Dense(20, activation='relu')(hidden_9)\n\n    output = Dense(1, activation='sigmoid')(hidden_10)\n\n    # Build the model\n    model = Model(inputs=[whole_text_input] + sentence_inputs, outputs=output)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T03:04:52.335373Z","iopub.execute_input":"2023-04-23T03:04:52.335843Z","iopub.status.idle":"2023-04-23T03:04:52.348703Z","shell.execute_reply.started":"2023-04-23T03:04:52.335806Z","shell.execute_reply":"2023-04-23T03:04:52.347259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"X_train_embeddings shape:\", X_train_embeddings.shape)\nprint(\"X_val_embeddings shape:\", X_val_embeddings.shape)\nprint(\"X_train_sentence_embeddings shapes:\", [x.shape for x in X_train_sentence_embeddings])\nprint(\"X_val_sentence_embeddings shapes:\", [x.shape for x in X_val_sentence_embeddings])\nprint(\"y_train shape:\", y_train.shape)\nprint(\"y_val shape:\", y_val.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T03:04:54.482980Z","iopub.execute_input":"2023-04-23T03:04:54.483498Z","iopub.status.idle":"2023-04-23T03:04:54.491846Z","shell.execute_reply.started":"2023-04-23T03:04:54.483445Z","shell.execute_reply":"2023-04-23T03:04:54.490765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam\n\n# Use MirroredStrategy for multi-GPU training\nstrategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\nprint(f\"Number of devices: {strategy.num_replicas_in_sync}\")\n\nwith strategy.scope():\n    # Build the model\n    model = build_model()\n\n    # Compile the model\n    model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(\n    [X_train_embeddings] + X_train_sentence_embeddings, y_train,\n    validation_data=([X_val_embeddings] + X_val_sentence_embeddings, y_val),\n    epochs=30,\n    batch_size=16\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T03:10:38.408866Z","iopub.execute_input":"2023-04-23T03:10:38.409468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-04-22T20:06:52.087013Z","iopub.execute_input":"2023-04-22T20:06:52.087529Z","iopub.status.idle":"2023-04-22T20:06:52.190441Z","shell.execute_reply.started":"2023-04-22T20:06:52.087488Z","shell.execute_reply":"2023-04-22T20:06:52.189063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}